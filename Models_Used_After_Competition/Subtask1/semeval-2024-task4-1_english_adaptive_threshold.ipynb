{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:27:14.448637Z","iopub.status.busy":"2024-01-12T10:27:14.447762Z","iopub.status.idle":"2024-01-12T10:27:33.631891Z","shell.execute_reply":"2024-01-12T10:27:33.631041Z","shell.execute_reply.started":"2024-01-12T10:27:14.448599Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import PIL\n","import torchvision\n","import numpy\n","import pandas\n","import torch \n","import torch.optim as optim\n","import gc\n","from torch.optim.lr_scheduler import StepLR\n","import cv2\n","import os\n","import json\n","import numpy as np\n","from transformers import BertModel, BertTokenizer\n","import torch\n","import matplotlib.pyplot as plt\n","from transformers import AutoTokenizer, AutoModel\n","from transformers import T5EncoderModel\n","from transformers import GPT2Tokenizer, GPT2Model\n","from transformers import ViTImageProcessor, ViTModel\n","from PIL import Image\n","import requests\n","from tqdm import tqdm\n","import re \n","import string "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:27:33.635034Z","iopub.status.busy":"2024-01-12T10:27:33.633874Z","iopub.status.idle":"2024-01-12T10:27:33.643307Z","shell.execute_reply":"2024-01-12T10:27:33.642244Z","shell.execute_reply.started":"2024-01-12T10:27:33.634995Z"},"trusted":true},"outputs":[],"source":["PATH_DATASETS = \"../datasets\"\n","PATH_JSON_TRAIN = os.path.join(PATH_DATASETS, \"data/subtask1/train.json\") \n","PATH_JSON_VAL = os.path.join(PATH_DATASETS, \"data/subtask1/validation.json\") \n","PATH_JSON_DEV = os.path.join(PATH_DATASETS, \"dev_gold_labels/dev_subtask1_en.json\") \n","PATH_JSON_TEST = os.path.join(PATH_DATASETS, \"test_data/english/en_subtask1_test_unlabeled.json\") \n","\n","PATH_SAVE_MODEL = \"subtask1_models\"\n","PATH_SAVE_SUBMISSION = \"subtask1_submissions\"\n","\n","os.makedirs(PATH_SAVE_MODEL, exist_ok=True)\n","os.makedirs(PATH_SAVE_SUBMISSION, exist_ok=True)\n","\n","BERT_MODEL = 'limjiayi/bert-hateful-memes-expanded' \n","NUM_CLASSES = 20\n","\n","BATCH_SIZE = 8\n","\n","EPOCHS_FULL = 3\n","LR_FULL = 1e-5\n","\n","EPOCHS_FC = 3\n","LR_FC = 3e-6\n","\n","TRAIN_ALL = True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:27:33.645114Z","iopub.status.busy":"2024-01-12T10:27:33.644706Z","iopub.status.idle":"2024-01-12T10:27:33.760020Z","shell.execute_reply":"2024-01-12T10:27:33.758834Z","shell.execute_reply.started":"2024-01-12T10:27:33.645077Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'id': '65635', 'text': 'THIS IS WHY YOU NEED\\\\n\\\\nA SHARPIE WITH YOU AT ALL TIMES', 'labels': ['Black-and-white Fallacy/Dictatorship'], 'link': 'https://www.facebook.com/photo/?fbid=4023552137722493&set=g.633131750534436'}\n"]}],"source":["data = json.load(open(PATH_JSON_TRAIN,\"r\",encoding='utf-8'))\n","\n","print(data[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:27:33.763611Z","iopub.status.busy":"2024-01-12T10:27:33.762611Z","iopub.status.idle":"2024-01-12T10:27:33.768327Z","shell.execute_reply":"2024-01-12T10:27:33.767242Z","shell.execute_reply.started":"2024-01-12T10:27:33.763577Z"},"trusted":true},"outputs":[],"source":["def preprocess(text):\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:27:33.770458Z","iopub.status.busy":"2024-01-12T10:27:33.770143Z","iopub.status.idle":"2024-01-12T10:27:38.061987Z","shell.execute_reply":"2024-01-12T10:27:38.061073Z","shell.execute_reply.started":"2024-01-12T10:27:33.770433Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertModel were not initialized from the model checkpoint at limjiayi/bert-hateful-memes-expanded and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)\n","text_model = AutoModel.from_pretrained(BERT_MODEL)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:27:38.064141Z","iopub.status.busy":"2024-01-12T10:27:38.063478Z","iopub.status.idle":"2024-01-12T10:27:38.076195Z","shell.execute_reply":"2024-01-12T10:27:38.075157Z","shell.execute_reply.started":"2024-01-12T10:27:38.064093Z"},"trusted":true},"outputs":[],"source":["class MyDataset(Dataset):\n","    \n","    def __init__(self, paths_json, bin_classes):\n","        self.texts = []\n","        self.ids = []\n","        self.labels = []\n","        \n","        for path_json in paths_json:\n","            data = json.load(open(path_json,\"r\",encoding='utf-8'))\n","\n","            for x in tqdm(data):\n","                self.ids.append(x['id'])\n","\n","                if 'labels' in x:\n","                    curr_labels = []\n","                    for bin_class in bin_classes:\n","                        if bin_class in x['labels']:\n","                            curr_labels.append(1)\n","                        else:\n","                            curr_labels.append(0)\n","                    self.labels.append(curr_labels)\n","                else:\n","                    self.labels.append([])\n","\n","                text = preprocess(x['text'])\n","                if text is None:\n","                    text = \"\"\n","                self.texts.append(tokenizer(text,return_tensors='pt',padding='max_length',max_length=128,truncation=True))\n","\n","    def __len__(self):\n","        return len(self.texts)\n","    \n","    def __getitem__(self,idx):\n","        text_tensors = {}\n","        for key, value in self.texts[idx].items():\n","            text_tensors[key] = value.cuda() if isinstance(value, torch.Tensor) else value\n","        \n","        return (text_tensors,torch.tensor(self.labels[idx]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:27:38.077706Z","iopub.status.busy":"2024-01-12T10:27:38.077356Z","iopub.status.idle":"2024-01-12T10:27:38.095446Z","shell.execute_reply":"2024-01-12T10:27:38.094298Z","shell.execute_reply.started":"2024-01-12T10:27:38.077667Z"},"trusted":true},"outputs":[],"source":["#torchvision.models.efficientnet_b0(pretrained=True)\n","class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        # Define text and image encoders\n","        self.text_encoder = AutoModel.from_pretrained(BERT_MODEL)\n","        \n","        self.fc = nn.Linear(98304, NUM_CLASSES)  # Adjust num_classes accordingly\n","    def forward(self,text_input):\n","        # Process text input\n","        \n","        text_outputs = []\n","\n","        for i in range(text_input['input_ids'].shape[0]):\n","            x = dict()\n","            x['input_ids'] = text_input['input_ids'][i]\n","            x['token_type_ids'] = text_input['token_type_ids'][i]\n","            x['attention_mask'] = text_input['attention_mask'][i]\n","            text_outputs.append(self.text_encoder(**x).last_hidden_state)\n","            \n","            \n","        text_outputs = torch.stack(text_outputs)\n","        # Flatten and concatenate the outputs\n","        text_outputs = text_outputs.view(text_outputs.size(0), -1)\n","        \n","        # Pass through fully connected layer\n","        output = nn.Sigmoid()(self.fc(nn.Tanh()(text_outputs)))\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:27:38.096925Z","iopub.status.busy":"2024-01-12T10:27:38.096567Z","iopub.status.idle":"2024-01-12T10:27:38.154147Z","shell.execute_reply":"2024-01-12T10:27:38.153071Z","shell.execute_reply.started":"2024-01-12T10:27:38.096897Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["20\n","['Black-and-white Fallacy/Dictatorship', 'Loaded Language', 'Glittering generalities (Virtue)', 'Thought-terminating cliché', 'Whataboutism', 'Slogans', 'Causal Oversimplification', 'Smears', 'Name calling/Labeling', 'Appeal to authority', 'Exaggeration/Minimisation', 'Repetition', 'Flag-waving', 'Appeal to fear/prejudice', 'Reductio ad hitlerum', 'Doubt', \"Misrepresentation of Someone's Position (Straw Man)\", 'Obfuscation, Intentional vagueness, Confusion', 'Bandwagon', 'Presenting Irrelevant Data (Red Herring)']\n"]}],"source":["data = json.load(open(PATH_JSON_TRAIN,\"r\",encoding='utf-8'))\n","\n","bin_classes = []\n","\n","for x in data:\n","    for label in x['labels']:\n","        if label not in bin_classes:\n","            bin_classes.append(label)\n","\n","print(len(bin_classes))\n","print(bin_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:27:38.155579Z","iopub.status.busy":"2024-01-12T10:27:38.155308Z","iopub.status.idle":"2024-01-12T10:27:41.936574Z","shell.execute_reply":"2024-01-12T10:27:41.935452Z","shell.execute_reply.started":"2024-01-12T10:27:38.155555Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/7000 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 7000/7000 [00:00<00:00, 7935.52it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 8403.47it/s]\n","100%|██████████| 500/500 [00:00<00:00, 8770.14it/s]\n","100%|██████████| 500/500 [00:00<00:00, 8773.70it/s]\n","100%|██████████| 1500/1500 [00:00<00:00, 9147.08it/s]\n"]}],"source":["if TRAIN_ALL:\n","    train_data = MyDataset([PATH_JSON_TRAIN, PATH_JSON_DEV, PATH_JSON_VAL], bin_classes)\n","else:\n","    train_data = MyDataset([PATH_JSON_TRAIN, PATH_JSON_DEV], bin_classes)\n","valid_data = MyDataset([PATH_JSON_VAL], bin_classes)\n","test_data = MyDataset([PATH_JSON_TEST], bin_classes)\n","\n","train_dataloader = DataLoader(dataset = train_data, batch_size = BATCH_SIZE, shuffle = True)\n","valid_dataloader = DataLoader(dataset = valid_data, batch_size = BATCH_SIZE, shuffle = False)\n","test_dataloader = DataLoader(dataset = test_data, batch_size = 1, shuffle = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:27:41.940998Z","iopub.status.busy":"2024-01-12T10:27:41.940617Z","iopub.status.idle":"2024-01-12T10:27:41.946338Z","shell.execute_reply":"2024-01-12T10:27:41.945194Z","shell.execute_reply.started":"2024-01-12T10:27:41.940970Z"},"trusted":true},"outputs":[],"source":["# m = nn.Sigmoid()\n","# loss = nn.BCELoss()\n","# input = torch.randn(3, requires_grad=True)\n","# target = torch.empty(3).random_(2)\n","\n","# print(input)\n","# print(target)\n","# output = loss(m(input), target)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:27:41.950062Z","iopub.status.busy":"2024-01-12T10:27:41.949063Z","iopub.status.idle":"2024-01-12T10:47:42.601773Z","shell.execute_reply":"2024-01-12T10:47:42.600815Z","shell.execute_reply.started":"2024-01-12T10:27:41.949995Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["8500\n","torch.Size([1, 128])\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BertModel were not initialized from the model checkpoint at limjiayi/bert-hateful-memes-expanded and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","17it [00:03,  4.89it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[29], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     39\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 41\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m+\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Validation loop\u001b[39;00m\n\u001b[0;32m     44\u001b[0m validation_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["best_thresh_all = []\n","    \n","print(len(train_data))\n","print(train_data.texts[0]['input_ids'].shape)\n","\n","model = Model()\n","model.cuda()\n","model.train()\n","\n","criterion = torch.nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = LR_FULL)\n","\n","best_loss = 1e9\n","\n","for epoch in range(EPOCHS_FULL):\n","\n","    train_loss = 0.0    \n","    model.train()\n","    for useless_id, (texts_batch, labels_batch) in tqdm(enumerate(train_dataloader)):\n","        optimizer.zero_grad()\n","\n","        labels_batch = labels_batch.to(torch.float32)\n","        labels_batch = labels_batch.to('cuda')\n","\n","        labels_predictions = model(texts_batch)\n","\n","#         print(labels_predictions.shape)\n","#         print(labels_batch.shape)\n","        \n","#         print(labels_predictions.type())\n","#         print(labels_batch.type())\n","        \n","#         print(labels_predictions)\n","#         print(labels_batch)\n","        \n","        loss = criterion(labels_predictions, labels_batch)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        train_loss = train_loss + loss.item()\n","\n","    # Validation loop\n","    validation_loss = 0.0\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    all_val_pred = [[] for _ in range(NUM_CLASSES)] \n","    all_val_gt = [[] for _ in range(NUM_CLASSES)] \n","\n","    for useless_id, (texts_batch, labels_batch) in tqdm(enumerate(valid_dataloader)):\n","        labels_batch = labels_batch.to(torch.float32)\n","        labels_batch = labels_batch.to('cuda')\n","        labels_predictions = model(texts_batch)\n","\n","        loss = criterion(labels_predictions, labels_batch)\n","\n","\n","        validation_loss = validation_loss + loss.item()\n","\n","\n","        predicted = (labels_predictions > 0.5)\n","        \n","        total += labels_batch.size(0)\n","        correct += (predicted == labels_batch).sum().item()\n","\n","        cpu_labels_predictions = labels_predictions.to('cpu').tolist()\n","        cpu_labels_batch = labels_batch.to('cpu').tolist()\n","\n","        for bat in range(len(cpu_labels_predictions)):\n","            for i in range(NUM_CLASSES):\n","                all_val_pred[i].append(cpu_labels_predictions[bat][i])\n","                all_val_gt[i].append(cpu_labels_batch[bat][i])\n","\n","    best_thresh_all = []\n","    print(\"BEST THRESHOLDS\")\n","    for i in range(NUM_CLASSES):\n","        zipped_pred_gt = list(zip(all_val_pred[i], all_val_gt[i]))\n","        zipped_pred_gt.sort()\n","\n","        best_thresh = 0\n","        best_f1 = 0\n","        tp = sum(all_val_gt[i])\n","        fp = len(all_val_gt[i]) - tp\n","        fn = 0\n","        for x in zipped_pred_gt:\n","            if x[1] == 1:\n","                tp -= 1\n","                fn += 1\n","            else:\n","                fp -= 1\n","\n","            if tp > 0:\n","                curr_f1 = 2*tp / (2*tp + fp + fn)\n","                if curr_f1 > best_f1:\n","                    best_f1 = curr_f1\n","                    best_thresh = x[0] \n","        best_thresh_all.append(best_thresh)\n","\n","        print(f\"{bin_classes[i]} : best_thresh={best_thresh} , best_f1={best_f1}\")\n","    print()\n","\n","    train_loss /= len(train_dataloader.dataset)\n","    validation_loss /= len(train_dataloader.dataset)\n","    accuracy = (correct / total) / len(bin_classes)\n","    print(f'Epoch: {epoch} Train Loss: {train_loss} Validation Loss: {validation_loss} Validation Accuracy: {accuracy * 100:.2f}%')\n","\n","    # Save checkpoint if needed\n","    # checkpoint = {'checkpoint': model.state_dict()}\n","    # torch.save(checkpoint, os.path.join(PATH_SAVE_MODEL, f'checkpoint_{epoch}.pt'))\n","    print(f'Checkpoint reached! Validation loss modified from {best_loss} to {validation_loss}')\n","    best_loss = validation_loss\n","    torch.cuda.empty_cache()\n","                    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:47:42.604319Z","iopub.status.busy":"2024-01-12T10:47:42.604005Z","iopub.status.idle":"2024-01-12T10:55:25.651123Z","shell.execute_reply":"2024-01-12T10:55:25.649970Z","shell.execute_reply.started":"2024-01-12T10:47:42.604294Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["1000it [00:43, 23.17it/s]\n","63it [00:02, 24.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["BEST THRESHOLDS\n","Black-and-white Fallacy/Dictatorship : best_thresh=0.1474543809890747 , best_f1=0.45569620253164556\n","Loaded Language : best_thresh=0.28121861815452576 , best_f1=0.56875\n","Glittering generalities (Virtue) : best_thresh=0.4378505051136017 , best_f1=0.4918032786885246\n","Thought-terminating cliché : best_thresh=0.3190999925136566 , best_f1=0.39473684210526316\n","Whataboutism : best_thresh=0.1247732862830162 , best_f1=0.27450980392156865\n","Slogans : best_thresh=0.31313225626945496 , best_f1=0.47191011235955055\n","Causal Oversimplification : best_thresh=0.18258559703826904 , best_f1=0.22857142857142856\n","Smears : best_thresh=0.16772451996803284 , best_f1=0.5794871794871795\n","Name calling/Labeling : best_thresh=0.34608033299446106 , best_f1=0.64\n","Appeal to authority : best_thresh=0.1932286024093628 , best_f1=0.7692307692307693\n","Exaggeration/Minimisation : best_thresh=0.2341528683900833 , best_f1=0.5777777777777777\n","Repetition : best_thresh=0.1865023374557495 , best_f1=0.625\n","Flag-waving : best_thresh=0.40521442890167236 , best_f1=0.5679012345679012\n","Appeal to fear/prejudice : best_thresh=0.0782914087176323 , best_f1=0.3157894736842105\n","Reductio ad hitlerum : best_thresh=0.08387669175863266 , best_f1=0.5\n","Doubt : best_thresh=0.10863467305898666 , best_f1=0.3076923076923077\n","Misrepresentation of Someone's Position (Straw Man) : best_thresh=0.03923540189862251 , best_f1=0.1\n","Obfuscation, Intentional vagueness, Confusion : best_thresh=0.007847768254578114 , best_f1=0.06896551724137931\n","Bandwagon : best_thresh=0.3570820093154907 , best_f1=0.6\n","Presenting Irrelevant Data (Red Herring) : best_thresh=0.03662269189953804 , best_f1=0.13793103448275862\n","\n","Epoch: 0 Train Loss: 0.01095566082163714 Validation Loss: 0.0016120926206931471 Validation Accuracy: 92.55%\n","Checkpoint reached! Validation loss modified from 1000000000.0 to 0.0016120926206931471\n"]},{"name":"stderr","output_type":"stream","text":["1000it [00:43, 23.14it/s]\n","63it [00:02, 24.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["BEST THRESHOLDS\n","Black-and-white Fallacy/Dictatorship : best_thresh=0.1661970317363739 , best_f1=0.4594594594594595\n","Loaded Language : best_thresh=0.23600409924983978 , best_f1=0.573208722741433\n","Glittering generalities (Virtue) : best_thresh=0.4518183767795563 , best_f1=0.5079365079365079\n","Thought-terminating cliché : best_thresh=0.3465636968612671 , best_f1=0.38961038961038963\n","Whataboutism : best_thresh=0.13569805026054382 , best_f1=0.2641509433962264\n","Slogans : best_thresh=0.06287406384944916 , best_f1=0.4782608695652174\n","Causal Oversimplification : best_thresh=0.2181524634361267 , best_f1=0.25\n","Smears : best_thresh=0.12356071174144745 , best_f1=0.5728643216080402\n","Name calling/Labeling : best_thresh=0.3214830756187439 , best_f1=0.6462882096069869\n","Appeal to authority : best_thresh=0.2365138828754425 , best_f1=0.7769784172661871\n","Exaggeration/Minimisation : best_thresh=0.2879684269428253 , best_f1=0.5581395348837209\n","Repetition : best_thresh=0.20679157972335815 , best_f1=0.6086956521739131\n","Flag-waving : best_thresh=0.4439813196659088 , best_f1=0.5641025641025641\n","Appeal to fear/prejudice : best_thresh=0.0835644006729126 , best_f1=0.29545454545454547\n","Reductio ad hitlerum : best_thresh=0.09817039966583252 , best_f1=0.4444444444444444\n","Doubt : best_thresh=0.3326203227043152 , best_f1=0.3181818181818182\n","Misrepresentation of Someone's Position (Straw Man) : best_thresh=0.038121454417705536 , best_f1=0.10526315789473684\n","Obfuscation, Intentional vagueness, Confusion : best_thresh=0.006399969570338726 , best_f1=0.06666666666666667\n","Bandwagon : best_thresh=0.3862636983394623 , best_f1=0.6\n","Presenting Irrelevant Data (Red Herring) : best_thresh=0.0270620658993721 , best_f1=0.12903225806451613\n","\n","Epoch: 1 Train Loss: 0.01031054203514941 Validation Loss: 0.001658263286575675 Validation Accuracy: 92.50%\n","Checkpoint reached! Validation loss modified from 0.0016120926206931471 to 0.001658263286575675\n"]},{"name":"stderr","output_type":"stream","text":["1000it [00:43, 23.15it/s]\n","63it [00:02, 24.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["BEST THRESHOLDS\n","Black-and-white Fallacy/Dictatorship : best_thresh=0.1665106564760208 , best_f1=0.4657534246575342\n","Loaded Language : best_thresh=0.19219794869422913 , best_f1=0.5680473372781065\n","Glittering generalities (Virtue) : best_thresh=0.4044259786605835 , best_f1=0.5079365079365079\n","Thought-terminating cliché : best_thresh=0.35019129514694214 , best_f1=0.4166666666666667\n","Whataboutism : best_thresh=0.11264052242040634 , best_f1=0.2692307692307692\n","Slogans : best_thresh=0.04442925006151199 , best_f1=0.48\n","Causal Oversimplification : best_thresh=0.1684967428445816 , best_f1=0.22857142857142856\n","Smears : best_thresh=0.1516617238521576 , best_f1=0.5737704918032787\n","Name calling/Labeling : best_thresh=0.3283158242702484 , best_f1=0.6375545851528385\n","Appeal to authority : best_thresh=0.23459598422050476 , best_f1=0.7769784172661871\n","Exaggeration/Minimisation : best_thresh=0.24717316031455994 , best_f1=0.5652173913043478\n","Repetition : best_thresh=0.20218044519424438 , best_f1=0.6086956521739131\n","Flag-waving : best_thresh=0.31305378675460815 , best_f1=0.5681818181818182\n","Appeal to fear/prejudice : best_thresh=0.251982182264328 , best_f1=0.2916666666666667\n","Reductio ad hitlerum : best_thresh=0.0648965910077095 , best_f1=0.5\n","Doubt : best_thresh=0.12918420135974884 , best_f1=0.3116883116883117\n","Misrepresentation of Someone's Position (Straw Man) : best_thresh=0.035431552678346634 , best_f1=0.09090909090909091\n","Obfuscation, Intentional vagueness, Confusion : best_thresh=0.004953750409185886 , best_f1=0.06060606060606061\n","Bandwagon : best_thresh=0.18214985728263855 , best_f1=0.5454545454545454\n","Presenting Irrelevant Data (Red Herring) : best_thresh=0.023360857740044594 , best_f1=0.125\n","\n","Epoch: 2 Train Loss: 0.009839921128470451 Validation Loss: 0.0016923312237486243 Validation Accuracy: 92.47%\n","Checkpoint reached! Validation loss modified from 0.001658263286575675 to 0.0016923312237486243\n","Checkpoint reached! Validation loss modified from 0.0016923312237486243 to 0.0016923312237486243\n"]}],"source":["for param in model.text_encoder.parameters():\n","    param.requires_grad = False\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr = LR_FC)\n","best_loss = 1e9\n","\n","\n","for epoch in range(EPOCHS_FC):\n","\n","    train_loss = 0.0    \n","    model.train()\n","    for useless_id, (texts_batch, labels_batch) in tqdm(enumerate(train_dataloader)):\n","        optimizer.zero_grad()\n","\n","        labels_batch = labels_batch.to(torch.float32)\n","        labels_batch = labels_batch.to('cuda')\n","\n","        labels_predictions = model(texts_batch)\n","\n","        loss = criterion(labels_predictions, labels_batch)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        train_loss = train_loss + loss.item()\n","\n","    # Validation loop\n","    validation_loss = 0.0\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    all_val_pred = [[] for _ in range(NUM_CLASSES)] \n","    all_val_gt = [[] for _ in range(NUM_CLASSES)] \n","\n","    for useless_id, (texts_batch, labels_batch) in tqdm(enumerate(valid_dataloader)):\n","        labels_batch = labels_batch.to(torch.float32)\n","        labels_batch = labels_batch.to('cuda')\n","        labels_predictions = model(texts_batch)\n","\n","        loss = criterion(labels_predictions, labels_batch)\n","\n","\n","        validation_loss = validation_loss + loss.item()\n","\n","\n","        predicted = (labels_predictions > 0.5)\n","        \n","        total += labels_batch.size(0)\n","        correct += (predicted == labels_batch).sum().item()\n","\n","        cpu_labels_predictions = labels_predictions.to('cpu').tolist()\n","        cpu_labels_batch = labels_batch.to('cpu').tolist()\n","\n","        for bat in range(len(cpu_labels_predictions)):\n","            for i in range(NUM_CLASSES):\n","                all_val_pred[i].append(cpu_labels_predictions[bat][i])\n","                all_val_gt[i].append(cpu_labels_batch[bat][i])\n","\n","    best_thresh_all = []\n","    print(\"BEST THRESHOLDS\")\n","    for i in range(NUM_CLASSES):\n","        zipped_pred_gt = list(zip(all_val_pred[i], all_val_gt[i]))\n","        zipped_pred_gt.sort()\n","\n","        best_thresh = 0\n","        best_f1 = 0\n","        tp = sum(all_val_gt[i])\n","        fp = len(all_val_gt[i]) - tp\n","        fn = 0\n","        for x in zipped_pred_gt:\n","            if x[1] == 1:\n","                tp -= 1\n","                fn += 1\n","            else:\n","                fp -= 1\n","\n","            if tp > 0:\n","                curr_f1 = 2*tp / (2*tp + fp + fn)\n","                if curr_f1 > best_f1:\n","                    best_f1 = curr_f1\n","                    best_thresh = x[0] \n","        best_thresh_all.append(best_thresh)\n","\n","        print(f\"{bin_classes[i]} : best_thresh={best_thresh} , best_f1={best_f1}\")\n","    print()\n","\n","    train_loss /= len(train_dataloader.dataset)\n","    validation_loss /= len(train_dataloader.dataset)\n","    accuracy = (correct / total) / len(bin_classes)\n","    print(f'Epoch: {epoch} Train Loss: {train_loss} Validation Loss: {validation_loss} Validation Accuracy: {accuracy * 100:.2f}%')\n","\n","    # Save checkpoint if needed\n","    # checkpoint = {'checkpoint': model.state_dict()}\n","    # torch.save(checkpoint, os.path.join(PATH_SAVE_MODEL, f'checkpoint_{epoch}.pt'))\n","    print(f'Checkpoint reached! Validation loss modified from {best_loss} to {validation_loss}')\n","    best_loss = validation_loss\n","    torch.cuda.empty_cache()\n","\n","\n","\n","# Save checkpoint if needed\n","# checkpoint = {'checkpoint': model.state_dict()}\n","# torch.save(checkpoint, os.path.join(PATH_SAVE_MODEL, f'fc_checkpoint_{epoch}.pt'))\n","print(f'Checkpoint reached! Validation loss modified from {best_loss} to {validation_loss}')\n","best_loss = validation_loss\n","torch.cuda.empty_cache()\n","\n","checkpoint = {'checkpoint': model.state_dict()}\n","torch.save(checkpoint, os.path.join(PATH_SAVE_MODEL, f'checkpoint.pt'))\n","\n","#import torch\n","# model.train()\n","# checkpoint = torch.load(os.path.join(PATH_SAVE_MODEL, f'fc_checkpoint_{4}.pt'))\n","\n","# # Apply the state dictionary to the model\n","# model.load_state_dict(checkpoint['checkpoint'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.1665106564760208, 0.19219794869422913, 0.4044259786605835, 0.35019129514694214, 0.11264052242040634, 0.04442925006151199, 0.1684967428445816, 0.1516617238521576, 0.3283158242702484, 0.23459598422050476, 0.24717316031455994, 0.20218044519424438, 0.31305378675460815, 0.251982182264328, 0.0648965910077095, 0.12918420135974884, 0.035431552678346634, 0.004953750409185886, 0.18214985728263855, 0.023360857740044594]\n"]}],"source":["print(best_thresh_all)\n","\n","best_thresh_all = [0.1665106564760208, 0.19219794869422913, 0.4044259786605835, 0.35019129514694214, 0.11264052242040634, 0.04442925006151199, 0.1684967428445816, 0.1516617238521576, 0.3283158242702484, 0.23459598422050476, 0.24717316031455994, 0.20218044519424438, 0.31305378675460815, 0.251982182264328, 0.0648965910077095, 0.12918420135974884, 0.035431552678346634, 0.004953750409185886, 0.18214985728263855, 0.023360857740044594]\n","\n","best_thresh_all = [max(0.2, x) * 1 for x in best_thresh_all]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:55:25.653864Z","iopub.status.busy":"2024-01-12T10:55:25.653336Z","iopub.status.idle":"2024-01-12T10:55:38.347278Z","shell.execute_reply":"2024-01-12T10:55:38.345908Z","shell.execute_reply.started":"2024-01-12T10:55:25.653813Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["1500it [00:10, 146.34it/s]\n"]}],"source":["predictions = {}\n","ids = []\n","\n","for useless_id, (texts_batch, labels_batch) in tqdm(enumerate(test_dataloader)):\n","    model.eval()\n","\n","    labels_predictions = model(texts_batch)\n","\n","\n","    predicted = labels_predictions[0]\n","    \n","    curr_id = test_data.ids[useless_id]\n","    if curr_id not in predictions:\n","        predictions[curr_id] = []\n","        \n","    idx_bin_class = 0\n","    for bin_class in bin_classes:\n","        if predicted[idx_bin_class] > best_thresh_all[idx_bin_class]:\n","            predictions[curr_id].append(bin_class)\n","        idx_bin_class += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-12T10:55:38.349243Z","iopub.status.busy":"2024-01-12T10:55:38.348856Z","iopub.status.idle":"2024-01-12T10:55:38.372954Z","shell.execute_reply":"2024-01-12T10:55:38.371579Z","shell.execute_reply.started":"2024-01-12T10:55:38.349215Z"},"trusted":true},"outputs":[],"source":["output_json = []\n","for k,v in predictions.items():\n","    output_json.append({\"id\" : k, \"labels\" : v})\n","\n","with open(os.path.join(PATH_SAVE_SUBMISSION, \"submission.txt\"),\"w\") as fout:\n","    json.dump(output_json, fout)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4291150,"sourceId":7383307,"sourceType":"datasetVersion"}],"dockerImageVersionId":30635,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
